{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ml libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "# scores\n",
    "from sklearn.metrics import mean_squared_error,mean_squared_log_error,confusion_matrix,accuracy_score,roc_auc_score, balanced_accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing(object):\n",
    "    def __init__(self, test_size=0.2, random_state=4):\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # get numeric and categorical columns\n",
    "        categorical_columns = []\n",
    "        numeric_columns = []\n",
    "        for c in X.columns:\n",
    "            if X[c].map(type).eq(str).any(): #check if there are any strings in column\n",
    "                categorical_columns.append(c)\n",
    "            else:\n",
    "                numeric_columns.append(c)\n",
    "\n",
    "        # create two DataFrames - categorical and numerical \n",
    "        data_numeric = X[numeric_columns]\n",
    "        data_categorical = pd.DataFrame(X[categorical_columns])\n",
    "        \n",
    "        # impute missing values\n",
    "        imp = Imputer(missing_values=np.nan, strategy='median', axis=0)\n",
    "        data_numeric = pd.DataFrame(imp.fit_transform(data_numeric), columns = data_numeric.columns) #only apply imputer to numeric columns\n",
    "\n",
    "        # no missing values in the categorical features as per the initial investigation \n",
    "\n",
    "        # join the two masked dataframes back together\n",
    "        data_joined = pd.concat([data_numeric, data_categorical], axis = 1)\n",
    "        \n",
    "        \n",
    "        data_joined.num_employees = data_joined.num_employees.replace({\"None\":0,\"1\":1,\"2to5\":4,\"6to10\":8,\"11to50\":32,\"50plus\":60})\n",
    "        data_joined.num_purchases_year = data_joined.num_purchases_year.replace({'1to2':1, '25plus':32, '3to5':4, '11to25':16, 'None':0, '6to10':8})\n",
    "        data_joined.cost_purchases_year = data_joined.cost_purchases_year.replace({'lessthan1':1, '25to100':64, '1to5':4, '5to25':16, 'None':0, '100plus':126})\n",
    "        \n",
    "        onehot_data = pd.get_dummies(data_joined, drop_first=True)\n",
    "        \n",
    "        X = onehot_data\n",
    "        y = onehot_data.convert_30\n",
    "        X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)\n",
    "        \n",
    "        # upsampling in training set\n",
    "        df_majority = X_train_class[X_train_class.convert_30==0]\n",
    "        df_minority = X_train_class[X_train_class.convert_30==1]\n",
    " \n",
    "        df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=20179, \n",
    "                                 random_state=12) \n",
    "        df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "        X_train_balance = df_upsampled.drop(['convert_30'], axis=1)\n",
    "        y_train_balance = df_upsampled.convert_30\n",
    "        \n",
    "        self.y_train_revenue = X_train_balance[\"revenue_30\"]\n",
    "        self.y_test_revenue = X_test_class[\"revenue_30\"]\n",
    "        \n",
    "        X_train_balance = X_train_balance.drop(['cuid','revenue_30','Unnamed: 0'], axis=1)\n",
    "        X_test_class = X_test_class.drop(['cuid','revenue_30','Unnamed: 0'], axis=1)\n",
    "        \n",
    "        X_test_class = X_test_class.drop(\"convert_30\",axis=1)\n",
    "        \n",
    "        self.X_train = X_train_balance\n",
    "        self.X_test = X_test_class\n",
    "        self.y_train_conv = y_train_balance\n",
    "        self.y_test_conv = y_test_class\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelection(object):\n",
    "    def __init__(self, selection_type = \"chi\", chi_k=30):\n",
    "        self.selection_type = selection_type\n",
    "        self.chi_k = chi_k\n",
    "    \n",
    "    def _chi(self, X, y):\n",
    "        X_norm = MinMaxScaler().fit_transform(X)\n",
    "        chi_selector = SelectKBest(chi2, k=self.chi_k)\n",
    "        chi_selector.fit(X_norm, y)\n",
    "        chi_support = chi_selector.get_support()\n",
    "        chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "        return chi_feature\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.selection_type == \"chi\":\n",
    "            return self._chi(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv(\"df_training_scholarjet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "data = preprocess.transform(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chi_features = fs.fit(data.X_train, data.y_train_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dayssincelastord',\n",
       " 'percdirtythirty',\n",
       " 'numvisitthreeone',\n",
       " 'numvisitseventhree',\n",
       " 'numvisitthirtyseven',\n",
       " 'numvisitsixtythirty',\n",
       " 'numloggedinone',\n",
       " 'numloggedinthreeone',\n",
       " 'numloggedinseventhree',\n",
       " 'numloggedinthirtyseven',\n",
       " 'numsecondsonsiteone',\n",
       " 'numsecondsonsiteseventhree',\n",
       " 'numsecondsonsitethirtyseven',\n",
       " 'numtotalpageviewsthirtyseven',\n",
       " 'numatcone',\n",
       " 'numatcthreeone',\n",
       " 'numatcseventhree',\n",
       " 'numatcthirtyseven',\n",
       " 'numideaboardseventhree',\n",
       " 'dayssincelastvisit',\n",
       " 'numsearchtermsthreeone',\n",
       " 'numsearchtermsthirtyseven',\n",
       " 'percsecondsinbound',\n",
       " 'percemailopenedone',\n",
       " 'percemailopenedthreeone',\n",
       " 'percemailopenedseventhree',\n",
       " 'percemailopenedthirtyseven',\n",
       " 'dayssinceenrollment',\n",
       " 'roll_up_Unmanaged',\n",
       " 'currentstatus_Enrolled']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.mean(data.X_train[chi_features[:-2]], axis=0)).T.to_csv(\"chi_means.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.std(data.X_train[chi_features[:-2]], axis=0)).T.to_csv(\"chi_std.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def _classify_fit(self, X, y):\n",
    "        self.classif_model = XGBClassifier(\n",
    "         learning_rate =0.1,\n",
    "         n_estimators=80,\n",
    "         max_depth=5,\n",
    "         min_child_weight=1,\n",
    "         gamma=0.8,\n",
    "         reg_alpha = 1.0,\n",
    "         reg_lambda = 1.0,\n",
    "         subsample=0.9,\n",
    "         colsample_bytree=0.8,\n",
    "         objective= 'binary:logistic',\n",
    "         nthread=4,\n",
    "         scale_pos_weight=1,\n",
    "         seed=27).fit(X, y)\n",
    "    \n",
    "    def _regress_fit(self, X, y):\n",
    "        self.regress_model = XGBRegressor(\n",
    "            learning_rate =0.1,\n",
    "            n_estimators=1000,\n",
    "            max_depth=7,\n",
    "            min_child_weight=10,\n",
    "            gamma=0,\n",
    "            reg_alpha = 1.0,\n",
    "            reg_lambda = 0.5,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            objective='reg:squarederror',\n",
    "            nthread=4,\n",
    "            scale_pos_weight=1,\n",
    "            seed=27).fit(X,y,eval_metric=\"rmse\")\n",
    "    \n",
    "    def fit(self, X, y_class, y_reg):\n",
    "        self._classify_fit(X, y_class)   \n",
    "        self._regress_fit(X, y_reg)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        # step 1\n",
    "        y_conv = self.classif_model.predict(X_copy)\n",
    "        X_copy.loc[:,\"conv\"] = y_conv\n",
    "\n",
    "        # separate out the ones and zeroes\n",
    "        X_copy_1 = X_copy[X_copy.conv == 1.0]\n",
    "        X_copy_1 = X_copy_1.drop([\"conv\"], axis=1)\n",
    "        X_copy_0 = X_copy[X_copy.conv == 0.0]\n",
    "        X_copy_0.loc[:,\"revenue\"] = 0.0\n",
    "\n",
    "        # step 2\n",
    "        y_rev = self.regress_model.predict(X_copy_1)\n",
    "        X_copy_1.loc[:, \"revenue\"] = y_rev\n",
    "\n",
    "        \n",
    "        # merge data\n",
    "        X_new = pd.concat([X_copy_0, X_copy_1], axis=0)\n",
    "\n",
    "        return y_conv, X_new.revenue\n",
    "    \n",
    "    def score(self, y_true_conv, y_pred_conv, y_true_revenue, y_pred_revenue):\n",
    "        metrics = {}\n",
    "        \n",
    "        metrics[\"conv_balanced_accuracy\"] = balanced_accuracy_score(y_true_conv, y_pred_conv)\n",
    "        metrics[\"revenue_rmse\"] = mean_squared_error(y_true_revenue, y_pred_revenue) ** 0.5\n",
    "        \n",
    "        response = pd.DataFrame({\"y_true_conv\": y_true_conv, \"y_pred_conv\": y_pred_conv, \"y_true_revenue\": y_true_revenue, \"y_pred_revenue\": y_pred_revenue})\n",
    "        \n",
    "        metrics[\"effort\"] = ((sum(response[(response.y_true_conv == 0.0) & (response.y_pred_conv == 1.0)].y_pred_revenue))/ sum(y_true_revenue)) * 100\n",
    "        \n",
    "        metrics[\"loss\"] = ((sum(response[(response.y_true_conv == 1.0) & (response.y_pred_conv == 0.0)].y_true_revenue)) / sum(y_true_revenue)) * 100\n",
    "        \n",
    "        metrics[\"total_true_revenue\"] = sum(y_true_revenue)\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/anaconda3/lib/python3.6/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "model = m.fit(data.X_train[chi_features], data.y_train_conv, data.y_train_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type _io.BufferedWriter)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-067dd3c906c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpkl_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pickle_model_temp.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type _io.BufferedWriter)"
     ]
    }
   ],
   "source": [
    "pkl_filename = \"pickle_model_temp.pkl\"\n",
    "with open(pkl_filename, 'wb') as file_model:\n",
    "    pickle.dump(model, file_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename_classify = \"pickle_model_classify.pkl\"\n",
    "with open(pkl_filename_classify, 'wb') as file1:\n",
    "    pickle.dump(model.classif_model, file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename_reg = \"pickle_model_reg.pkl\"\n",
    "with open(pkl_filename_reg, 'wb') as file2:\n",
    "    pickle.dump(model.regress_model, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(data.X_train[chi_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.score(data.y_train_conv.values, y_pred[0], data.y_train_revenue.values, y_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predtest = model.predict(data.X_test[chi_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = model.score(data.y_test_conv.values, y_predtest[0], data.y_test_revenue.values, y_predtest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_balanced_accuracy': 0.7920858318053421,\n",
       " 'revenue_rmse': 1317.4646835204394,\n",
       " 'effort': 0.07319139433440847,\n",
       " 'loss': 16.47931753331053,\n",
       " 'total_true_revenue': 14533372.877601676}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_balanced_accuracy': 0.7287240939126542,\n",
       " 'revenue_rmse': 507.7544853428297,\n",
       " 'effort': 22.9781469495759,\n",
       " 'loss': 24.199138520724585,\n",
       " 'total_true_revenue': 416890.98069999926}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=7, min_child_weight=10, missing=None, n_estimators=1000,\n",
       "             n_jobs=1, nthread=4, objective='reg:squarederror', random_state=0,\n",
       "             reg_alpha=1.0, reg_lambda=0.5, scale_pos_weight=1, seed=27,\n",
       "             silent=None, subsample=0.9, verbosity=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.regress_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
